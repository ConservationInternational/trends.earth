{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb4656df",
   "metadata": {},
   "source": [
    "# SDG 15.3.1 Error Recode Script Example\n",
    "\n",
    "This notebook demonstrates how to use the SDG 15.3.1 error recode script via the trends.earth API. The script supports both single-period and multi-period land degradation jobs and allows for recoding specific areas based on error polygons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31a1154",
   "metadata": {},
   "source": [
    "## 1. Setup Environment and Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d9ecc",
   "metadata": {},
   "source": [
    "Before running this notebook, make sure you have:\n",
    "\n",
    "1. **Installed dependencies**: `pip install -r requirements.txt`\n",
    "2. **Created environment file**: Copy `.env.example` to `.env` and update with your credentials:\n",
    "   ```bash\n",
    "   cp .env.example .env\n",
    "   ```\n",
    "3. **Updated credentials** in the `.env` file:\n",
    "   ```\n",
    "   API_BASE_URL=https://api.trends.earth\n",
    "   API_USERNAME=your_actual_username\n",
    "   API_PASSWORD=your_actual_password\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50c97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Environment variables loaded from .env file\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import uuid\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Import the shared API client\n",
    "import folium\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from trendsearth_api import TrendsEarthAPIClient\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Environment variables loaded from .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf01a26",
   "metadata": {},
   "source": [
    "## 2. Configure API Connection and Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323451c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using API URL from environment: https://api.trends.earth\n",
      "Authenticating with Trends.Earth API...\n",
      "   Using email: trends.earth-prais-server@trends.earth\n",
      "Successfully authenticated with Trends.Earth API\n",
      "Ready to submit error recode jobs!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the API client\n",
    "api_client = TrendsEarthAPIClient()\n",
    "\n",
    "# Authenticate using environment variables from .env file\n",
    "if api_client.authenticate_from_env():\n",
    "    print(\"Ready to submit error recode jobs!\")\n",
    "    session = api_client.session  # For compatibility with existing code\n",
    "else:\n",
    "    print(\"Authentication failed - check your .env file\")\n",
    "    print(\"Please ensure your .env file contains:\")\n",
    "    print(\"- API_USERNAME=your_username\")\n",
    "    print(\"- API_PASSWORD=your_password\")\n",
    "    print(\"- API_BASE_URL=https://api.trends.earth (optional)\")\n",
    "    session = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e8c81",
   "metadata": {},
   "source": [
    "## 3. Define Example Parameters for Error Recoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3871629",
   "metadata": {},
   "source": [
    "### Multi-period Data Support\n",
    "\n",
    "The  error recode script uses the `filters` parameter to select specific reporting periods for multi-period land degradation jobs:\n",
    "\n",
    "**For Single-period Jobs:**\n",
    "```python\n",
    "\"filters\": []  # No filters needed\n",
    "```\n",
    "\n",
    "**For Multi-period Jobs:**\n",
    "```python\n",
    "\"filters\": [{\"field\": \"reporting_year_final\", \"value\": 2020}]  # Target specific year\n",
    "```\n",
    "\n",
    "### Error Polygon Schema Requirements\n",
    "\n",
    "The error polygons must follow the trends.earth schema validation requirements:\n",
    "\n",
    "**Required Properties:**\n",
    "- `uuid`: A unique identifier (auto-generated UUID string)\n",
    "- `type`: Must be \"Feature\" for each feature\n",
    "\n",
    "**Optional Properties:**\n",
    "- `location_name`: Descriptive name for the error area\n",
    "- `area_km_sq`: Area in square kilometers\n",
    "- `process_driving_change`: Description of what caused the error\n",
    "- `basis_for_judgement`: Justification for the correction\n",
    "\n",
    "**Recode Options** (all optional, use None to leave unchanged):\n",
    "- `recode_deg_to`: What to recode degraded pixels to\n",
    "  - `None`: No change (default)\n",
    "  - `-32768`: No data\n",
    "  - `0`: Stable\n",
    "  - `1`: Improved\n",
    "- `recode_stable_to`: What to recode stable pixels to\n",
    "  - `None`: No change (default) \n",
    "  - `-32768`: No data\n",
    "  - `-1`: Degraded\n",
    "  - `1`: Improved\n",
    "- `recode_imp_to`: What to recode improved pixels to\n",
    "  - `None`: No change (default)\n",
    "  - `-32768`: No data\n",
    "  - `-1`: Degraded\n",
    "  - `0`: Stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dfdc9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ATG_polygon.geojson\", \"r\") as f:\n",
    "    atg_polygon = json.load(f)\n",
    "\n",
    "params = {\n",
    "    \"iso\": \"ATG\",\n",
    "    \"boundary_dataset\": \"UN\",\n",
    "    \"write_tifs\": False,\n",
    "    \"aoi\": json.dumps(atg_polygon),\n",
    "    \"error_polygons\": {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"name\": \"test error recode\",\n",
    "        \"crs\": {\n",
    "            \"type\": \"name\",\n",
    "            \"properties\": {\"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\"},\n",
    "        },\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {\n",
    "                    \"uuid\": str(uuid.uuid4()),\n",
    "                    \"location_name\": \"False degradation - mining misclassified\",\n",
    "                    \"area_km_sq\": 0.04,\n",
    "                    \"process_driving_change\": \"Open pit mining misclassified as degradation\",\n",
    "                    \"basis_for_judgement\": \"Ground truth verification shows managed mining operation\",\n",
    "                    \"recode_deg_to\": 0,  # Recode degraded pixels to stable\n",
    "                    \"recode_stable_to\": None,  # No change to stable pixels\n",
    "                    \"recode_imp_to\": None,  # No change to improved pixels\n",
    "                    \"periods_affected\": [\"baseline\"],\n",
    "                },\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"coordinates\": [\n",
    "                        [\n",
    "                            [-61.85, 17.05],\n",
    "                            [-61.8, 17.05],\n",
    "                            [-61.8, 17.1],\n",
    "                            [-61.85, 17.1],\n",
    "                            [-61.85, 17.05],\n",
    "                        ]\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {\n",
    "                    \"uuid\": str(uuid.uuid4()),\n",
    "                    \"location_name\": \"Restoration success not captured\",\n",
    "                    \"area_km_sq\": 0.02,\n",
    "                    \"process_driving_change\": \"Successful restoration not detected by algorithm\",\n",
    "                    \"basis_for_judgement\": \"Field monitoring shows vegetation recovery\",\n",
    "                    \"recode_deg_to\": 1,  # Recode degraded pixels to improved\n",
    "                    \"recode_stable_to\": 1,  # Also recode stable pixels to improved\n",
    "                    \"recode_imp_to\": None,  # Keep improved pixels as is\n",
    "                    \"periods_affected\": [\"baseline\", \"reporting_2\"],\n",
    "                },\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"coordinates\": [\n",
    "                        [\n",
    "                            [-61.82, 17.08],\n",
    "                            [-61.78, 17.08],\n",
    "                            [-61.78, 17.12],\n",
    "                            [-61.82, 17.12],\n",
    "                            [-61.82, 17.08],\n",
    "                        ]\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {\n",
    "                    \"uuid\": str(uuid.uuid4()),\n",
    "                    \"location_name\": \"Data quality issue\",\n",
    "                    \"area_km_sq\": 0.01,\n",
    "                    \"process_driving_change\": \"Cloud contamination in satellite data\",\n",
    "                    \"basis_for_judgement\": \"Visual inspection shows persistent cloud cover\",\n",
    "                    \"recode_deg_to\": -32768,  # Set all to no data due to poor data quality\n",
    "                    \"recode_stable_to\": -32768,  # Set all to no data\n",
    "                    \"recode_imp_to\": -32768,  # Set all to no data\n",
    "                    \"periods_affected\": [\"reporting_2\"],\n",
    "                },\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"coordinates\": [\n",
    "                        [\n",
    "                            [-61.88, 17.15],\n",
    "                            [-61.84, 17.15],\n",
    "                            [-61.84, 17.18],\n",
    "                            [-61.88, 17.18],\n",
    "                            [-61.88, 17.15],\n",
    "                        ]\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218d598",
   "metadata": {},
   "source": [
    "## 4. Submit Job Execution to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d0d24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job submitted. Monitoring job status...\n",
      "Status: READY\n",
      "Status: FAILED\n",
      "Job failed!\n"
     ]
    }
   ],
   "source": [
    "if api_client.access_token:\n",
    "    print(\" Submitting error recode job...\")\n",
    "    execution_id = api_client.submit_job(\"sdg-15-3-1-error-recode-2-1-17\", params)\n",
    "\n",
    "    if execution_id:\n",
    "        print(\"Job submitted. Monitoring job status...\")\n",
    "\n",
    "        # Monitor the job until completion\n",
    "        final_status = api_client.monitor_job(execution_id, max_minutes=15)\n",
    "\n",
    "        if final_status:\n",
    "            status = final_status.get(\"status\", \"unknown\").upper()\n",
    "            if status in [\"SUCCESS\", \"FINISHED\"]:\n",
    "                print(\"✅ Error recode job completed successfully!\")\n",
    "\n",
    "                # The results should be available in the job data\n",
    "                results = final_status.get(\"results\", {})\n",
    "                if results:\n",
    "                    print(\"Results available\")\n",
    "                    pprint(results)\n",
    "                else:\n",
    "                    print(\"No results data found in job response\")\n",
    "        else:\n",
    "            print(\"❌ Failed to monitor job\")\n",
    "    else:\n",
    "        print(\"❌ Failed to submit job\")\n",
    "else:\n",
    "    print(\"❌ Cannot submit job: not authenticated\")\n",
    "    print(\"Please check your credentials and authentication\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d3c6d9",
   "metadata": {},
   "source": [
    "## 6. Display JSON Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_summary(results):\n",
    "    \"\"\"Display a summary of the error recode results\"\"\"\n",
    "\n",
    "    if not results:\n",
    "        print(\"No results to display\")\n",
    "        return\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ERROR RECODE RESULTS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # General information\n",
    "    print(\"\\n📊 General Information:\")\n",
    "    print(f\"   Status: {results.get('status', 'Unknown')}\")\n",
    "\n",
    "    # Handle nested data structure\n",
    "    data_section = results.get(\"data\", results)\n",
    "\n",
    "    # Processing information\n",
    "    print(\"\\n📝 Processing Information:\")\n",
    "    if \"report\" in data_section:\n",
    "        print(f\"   Report: {data_section['report']}\")\n",
    "\n",
    "    if \"input_job\" in data_section:\n",
    "        input_job = data_section[\"input_job\"]\n",
    "        if isinstance(input_job, dict):\n",
    "            print(f\"   Task Name: {input_job.get('task_name', 'Unknown')}\")\n",
    "            print(\n",
    "                f\"   Input Band Index: {data_section.get('input_band_index', 'Unknown')}\"\n",
    "            )\n",
    "\n",
    "    # Look for results in both possible locations\n",
    "    raster_info = results.get(\"results\") or data_section.get(\"results\")\n",
    "\n",
    "    if raster_info:\n",
    "        print(\"\\n🗺️ Raster Output:\")\n",
    "        print(f\"   URI: {raster_info.get('uri', 'No URI available')}\")\n",
    "\n",
    "        if \"bands\" in raster_info:\n",
    "            bands = raster_info[\"bands\"]\n",
    "            print(f\"   Bands ({len(bands)}):\")\n",
    "            for i, band in enumerate(bands, 1):\n",
    "                print(f\"     {i}. {band.get('name', 'Unnamed band')}\")\n",
    "                print(f\"        Activated: {band.get('activated', False)}\")\n",
    "                if \"metadata\" in band:\n",
    "                    metadata = band[\"metadata\"]\n",
    "                    if \"reporting_year_final\" in metadata:\n",
    "                        print(\n",
    "                            f\"        Reporting Year: {metadata['reporting_year_final']}\"\n",
    "                        )\n",
    "\n",
    "    # Execution details (from API response)\n",
    "    if \"id\" in results:\n",
    "        print(\"\\n🔧 Execution Details:\")\n",
    "        print(f\"   Execution ID: {results.get('id')}\")\n",
    "        print(f\"   Script ID: {results.get('script_id', 'Unknown')}\")\n",
    "        print(f\"   User ID: {results.get('user_id', 'Unknown')}\")\n",
    "\n",
    "        if \"created_at\" in results:\n",
    "            print(f\"   Created: {results['created_at']}\")\n",
    "        if \"start_time\" in results:\n",
    "            print(f\"   Started: {results['start_time']}\")\n",
    "        if \"end_time\" in results:\n",
    "            print(f\"   Finished: {results['end_time']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "# Display the results\n",
    "if \"results\" in locals() and results:\n",
    "    display_results_summary(results)\n",
    "\n",
    "    print(\"\\n📋 Full JSON Results:\")\n",
    "    result_str = json.dumps(results, indent=2)\n",
    "    if len(result_str) > 1000:\n",
    "        print(result_str[:1000] + \"...\")\n",
    "        print(\n",
    "            f\"\\n[Truncated - showing first 1000 characters of {len(result_str)} total]\"\n",
    "        )\n",
    "    else:\n",
    "        print(result_str)\n",
    "else:\n",
    "    print(\"⚠️ No results available to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04201a14",
   "metadata": {},
   "source": [
    "## 7. Load and Visualize Raster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_error_recode_mask(error_polygons, raster_shape, extent):\n",
    "    \"\"\"Create a mask showing error recode areas\"\"\"\n",
    "\n",
    "    mask = np.zeros(raster_shape)\n",
    "\n",
    "    # Extract coordinates for demonstration\n",
    "    x_min, y_max, x_max, y_min = extent\n",
    "\n",
    "    # Handle GeoJSON FeatureCollection structure\n",
    "    features = error_polygons.get(\"features\", [])\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        geometry = feature[\"geometry\"]\n",
    "        properties = feature[\"properties\"]\n",
    "        coords = geometry[\"coordinates\"][0]\n",
    "\n",
    "        # Use property ID or index for recode value\n",
    "        recode_value = properties.get(\"id\", i + 1)\n",
    "\n",
    "        # Simple rectangular mask for demonstration\n",
    "        # In real implementation, you'd use proper polygon rasterization\n",
    "        for coord in coords:\n",
    "            lon, lat = coord\n",
    "\n",
    "            # Convert to array indices\n",
    "            col = int((lon - x_min) / (x_max - x_min) * raster_shape[1])\n",
    "            row = int((y_max - lat) / (y_max - y_min) * raster_shape[0])\n",
    "\n",
    "            # Create a small rectangular area around each coordinate\n",
    "            for dr in range(-5, 6):\n",
    "                for dc in range(-5, 6):\n",
    "                    r, c = row + dr, col + dc\n",
    "                    if 0 <= r < raster_shape[0] and 0 <= c < raster_shape[1]:\n",
    "                        mask[r, c] = recode_value + 2  # Offset for visualization\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def load_raster_from_uri(uri):\n",
    "    \"\"\"Load raster data from S3 URI or local path\"\"\"\n",
    "    try:\n",
    "        # For demonstration, we'll create synthetic data\n",
    "        # In real usage, you would load from the actual URI\n",
    "        print(f\"📁 Loading raster from: {uri}\")\n",
    "\n",
    "        if uri.startswith(\"s3://\"):\n",
    "            print(\"⚠️ S3 loading requires additional setup (AWS credentials, etc.)\")\n",
    "            print(\"Creating synthetic data for demonstration...\")\n",
    "\n",
    "            # Create synthetic land degradation data for Antigua and Barbuda coordinates\n",
    "            rows, cols = 100, 100\n",
    "            x = np.linspace(-61.9, -61.7, cols)  # Longitude range for ATG\n",
    "            y = np.linspace(17.2, 17.0, rows)  # Latitude range for ATG\n",
    "\n",
    "            # Create synthetic degradation pattern\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "\n",
    "            # Base degradation pattern\n",
    "            base_data = np.sin((X + 61.8) * 100) * np.cos((Y - 17.1) * 100) * 2\n",
    "\n",
    "            # Add some areas of improvement and degradation\n",
    "            degraded_mask = (X > -61.8) & (Y < 17.1)\n",
    "            improved_mask = (X < -61.85) & (Y > 17.15)\n",
    "\n",
    "            raster_data = np.where(\n",
    "                degraded_mask,\n",
    "                -1,  # Degraded\n",
    "                np.where(\n",
    "                    improved_mask,\n",
    "                    1,  # Improved\n",
    "                    0,\n",
    "                ),\n",
    "            )  # Stable\n",
    "\n",
    "            # Add some noise\n",
    "            noise = np.random.normal(0, 0.1, raster_data.shape)\n",
    "            raster_data = raster_data + noise\n",
    "\n",
    "            # Clip to valid range\n",
    "            raster_data = np.clip(raster_data, -1, 1)\n",
    "\n",
    "            return raster_data, (\n",
    "                x.min(),\n",
    "                y.max(),\n",
    "                x.max(),\n",
    "                y.min(),\n",
    "            )  # extent for plotting\n",
    "\n",
    "        else:\n",
    "            # Load from local file\n",
    "            if rasterio:\n",
    "                with rasterio.open(uri) as src:\n",
    "                    data = src.read(1)  # Read first band\n",
    "                    extent = [\n",
    "                        src.bounds.left,\n",
    "                        src.bounds.right,\n",
    "                        src.bounds.bottom,\n",
    "                        src.bounds.top,\n",
    "                    ]\n",
    "                    return data, extent\n",
    "            else:\n",
    "                print(\"⚠️ Rasterio not available for local file loading\")\n",
    "                return None, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading raster: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# Load the raster data\n",
    "if \"results\" in locals() and results:\n",
    "    # Handle both possible response structures\n",
    "    raster_data_section = results.get(\"results\") or results.get(\"data\", {}).get(\n",
    "        \"results\"\n",
    "    )\n",
    "    if raster_data_section and \"uri\" in raster_data_section:\n",
    "        raster_uri = raster_data_section[\"uri\"]\n",
    "    else:\n",
    "        raster_uri = \"synthetic_data\"  # Use synthetic data for demonstration\n",
    "else:\n",
    "    raster_uri = \"synthetic_data\"  # Use synthetic data for demonstration\n",
    "\n",
    "print(\"\\n🗺️ Loading raster data...\")\n",
    "raster_data, extent = load_raster_from_uri(raster_uri)\n",
    "\n",
    "if raster_data is not None:\n",
    "    print(\"✅ Raster loaded successfully!\")\n",
    "    print(f\"   Shape: {raster_data.shape}\")\n",
    "    print(f\"   Data range: {raster_data.min():.3f} to {raster_data.max():.3f}\")\n",
    "    print(f\"   Extent: {extent}\")\n",
    "\n",
    "    # Create error recode mask using the corrected error polygons structure\n",
    "    error_polygons_data = params[\"error_polygons\"]\n",
    "    error_mask = create_error_recode_mask(\n",
    "        error_polygons_data, raster_data.shape, extent\n",
    "    )\n",
    "    print(f\"   Error mask created with {np.sum(error_mask > 0)} pixels to recode\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Failed to load raster data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b722625f",
   "metadata": {},
   "source": [
    "## 8. Create Simple Maps from Raster Results\n",
    "\n",
    "Now let's create several visualization maps to show:\n",
    "1. Original land degradation status\n",
    "2. Error polygon locations and recode values  \n",
    "3. Side-by-side comparison\n",
    "4. Interactive map (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4630e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization maps\n",
    "if raster_data is not None:\n",
    "    # Set up the figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle(\n",
    "        \"SDG 15.3.1 Error Recode Analysis Results\", fontsize=16, fontweight=\"bold\"\n",
    "    )\n",
    "\n",
    "    # Define color maps and value ranges\n",
    "    degradation_colors = [\"darkred\", \"red\", \"yellow\", \"lightgreen\", \"darkgreen\"]\n",
    "    degradation_cmap = mcolors.ListedColormap(degradation_colors)\n",
    "    degradation_bounds = [-1, -0.5, -0.1, 0.1, 0.5, 1]\n",
    "    degradation_norm = mcolors.BoundaryNorm(degradation_bounds, degradation_cmap.N)\n",
    "\n",
    "    # 1. Original Land Degradation Status\n",
    "    ax1 = axes[0, 0]\n",
    "    im1 = ax1.imshow(\n",
    "        raster_data,\n",
    "        extent=extent,\n",
    "        cmap=degradation_cmap,\n",
    "        norm=degradation_norm,\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "    ax1.set_title(\"Original Land Degradation Status\", fontweight=\"bold\")\n",
    "    ax1.set_xlabel(\"Longitude\")\n",
    "    ax1.set_ylabel(\"Latitude\")\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar1 = plt.colorbar(im1, ax=ax1, shrink=0.8)\n",
    "    cbar1.set_label(\"Degradation Index\")\n",
    "    cbar1.set_ticks([-0.75, -0.3, 0, 0.3, 0.75])\n",
    "    cbar1.set_ticklabels([\"Degraded\", \"Declining\", \"Stable\", \"Improving\", \"Improved\"])\n",
    "\n",
    "    # 2. Error Polygon Locations\n",
    "    ax2 = axes[0, 1]\n",
    "    # Show base raster in grayscale\n",
    "    ax2.imshow(raster_data, extent=extent, cmap=\"gray\", alpha=0.3, aspect=\"auto\")\n",
    "\n",
    "    # Overlay error mask\n",
    "    error_cmap = plt.cm.Reds\n",
    "    masked_errors = np.ma.masked_where(error_mask == 0, error_mask)\n",
    "    im2 = ax2.imshow(\n",
    "        masked_errors, extent=extent, cmap=error_cmap, alpha=0.8, aspect=\"auto\"\n",
    "    )\n",
    "    ax2.set_title(\"Error Polygon Locations\", fontweight=\"bold\")\n",
    "    ax2.set_xlabel(\"Longitude\")\n",
    "    ax2.set_ylabel(\"Latitude\")\n",
    "\n",
    "    # Add colorbar for error polygons\n",
    "    cbar2 = plt.colorbar(im2, ax=ax2, shrink=0.8)\n",
    "    cbar2.set_label(\"Recode Value\")\n",
    "\n",
    "    # 3. Corrected Data (simulated)\n",
    "    ax3 = axes[1, 0]\n",
    "    # Apply corrections for demonstration\n",
    "    corrected_data = raster_data.copy()\n",
    "    correction_mask = error_mask > 0\n",
    "\n",
    "    # Apply different corrections based on recode values\n",
    "    for recode_val in [1, 2, 3]:  # Different recode values\n",
    "        mask = error_mask == (recode_val + 2)  # Offset applied earlier\n",
    "        if np.any(mask):\n",
    "            if recode_val == 1:  # Improve degraded areas\n",
    "                corrected_data[mask] = np.clip(corrected_data[mask] + 0.5, -1, 1)\n",
    "            elif recode_val == 2:  # Mark as stable\n",
    "                corrected_data[mask] = 0\n",
    "            elif recode_val == 3:  # Mark as degraded\n",
    "                corrected_data[mask] = -0.7\n",
    "\n",
    "    im3 = ax3.imshow(\n",
    "        corrected_data,\n",
    "        extent=extent,\n",
    "        cmap=degradation_cmap,\n",
    "        norm=degradation_norm,\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "    ax3.set_title(\"Corrected Land Degradation Status\", fontweight=\"bold\")\n",
    "    ax3.set_xlabel(\"Longitude\")\n",
    "    ax3.set_ylabel(\"Latitude\")\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar3 = plt.colorbar(im3, ax=ax3, shrink=0.8)\n",
    "    cbar3.set_label(\"Degradation Index\")\n",
    "    cbar3.set_ticks([-0.75, -0.3, 0, 0.3, 0.75])\n",
    "    cbar3.set_ticklabels([\"Degraded\", \"Declining\", \"Stable\", \"Improving\", \"Improved\"])\n",
    "\n",
    "    # 4. Difference Map (Before vs After)\n",
    "    ax4 = axes[1, 1]\n",
    "    difference = corrected_data - raster_data\n",
    "\n",
    "    # Use diverging colormap for differences\n",
    "    diff_cmap = plt.cm.RdBu_r\n",
    "    max_diff = np.abs(difference).max()\n",
    "    im4 = ax4.imshow(\n",
    "        difference,\n",
    "        extent=extent,\n",
    "        cmap=diff_cmap,\n",
    "        vmin=-max_diff,\n",
    "        vmax=max_diff,\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "    ax4.set_title(\"Correction Impact (After - Before)\", fontweight=\"bold\")\n",
    "    ax4.set_xlabel(\"Longitude\")\n",
    "    ax4.set_ylabel(\"Latitude\")\n",
    "\n",
    "    # Add colorbar for differences\n",
    "    cbar4 = plt.colorbar(im4, ax=ax4, shrink=0.8)\n",
    "    cbar4.set_label(\"Change in Degradation Index\")\n",
    "\n",
    "    # Add grid lines to all plots\n",
    "    for ax in axes.flat:\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(\"\\\\n📊 Correction Summary:\")\n",
    "    print(f\"   Total pixels: {raster_data.size:,}\")\n",
    "    print(f\"   Pixels corrected: {np.sum(correction_mask):,}\")\n",
    "    print(\n",
    "        f\"   Correction percentage: {100 * np.sum(correction_mask) / raster_data.size:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Mean change in degradation index: {difference[correction_mask].mean():.3f}\"\n",
    "    )\n",
    "    print(f\"   Max absolute change: {np.abs(difference).max():.3f}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot create maps - raster data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35df54f",
   "metadata": {},
   "source": [
    "## 9. Optional: Interactive Map with Folium\n",
    "\n",
    "Create an interactive map to explore the results in detail (requires folium installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508abf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive map using folium (requires folium installation)\n",
    "try:\n",
    "    # Center the map on Antigua and Barbuda\n",
    "    center_lat, center_lon = 17.1, -61.8\n",
    "\n",
    "    # Create the map\n",
    "    m = folium.Map(\n",
    "        location=[center_lat, center_lon], zoom_start=12, tiles=\"OpenStreetMap\"\n",
    "    )\n",
    "\n",
    "    # Add different base layers\n",
    "    folium.TileLayer(\"Stamen Terrain\").add_to(m)\n",
    "    folium.TileLayer(\"CartoDB positron\").add_to(m)\n",
    "\n",
    "    # Add AOI boundary - fix coordinates access for Feature format\n",
    "    aoi_coords = params[\"aoi\"][\"geometry\"][\"coordinates\"][0]  # Fixed: added 'geometry'\n",
    "    folium.Polygon(\n",
    "        locations=[[coord[1], coord[0]] for coord in aoi_coords],\n",
    "        color=\"blue\",\n",
    "        weight=2,\n",
    "        fill=True,\n",
    "        fillColor=\"blue\",\n",
    "        fillOpacity=0.1,\n",
    "        popup=\"Area of Interest (AOI)\",\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Add error polygon markers\n",
    "    error_features = params[\"error_polygons\"][\"features\"]\n",
    "    for i, feature in enumerate(error_features):\n",
    "        coords = feature[\"geometry\"][\"coordinates\"][0]\n",
    "        properties = feature[\"properties\"]\n",
    "        location_name = properties.get(\"location_name\", f\"Error Polygon {i + 1}\")\n",
    "        process_change = properties.get(\"process_driving_change\", \"Unknown\")\n",
    "        basis = properties.get(\"basis_for_judgement\", \"No basis provided\")\n",
    "        recode_deg = properties.get(\"recode_deg_to\", \"None\")\n",
    "        recode_stable = properties.get(\"recode_stable_to\", \"None\")\n",
    "        recode_imp = properties.get(\"recode_imp_to\", \"None\")\n",
    "\n",
    "        # Get center of polygon for marker\n",
    "        lons = [coord[0] for coord in coords]\n",
    "        lats = [coord[1] for coord in coords]\n",
    "        center_poly = [np.mean(lats), np.mean(lons)]\n",
    "\n",
    "        # Create popup content\n",
    "        popup_content = f\"\"\"\n",
    "        <b>{location_name}</b><br>\n",
    "        <b>Process:</b> {process_change}<br>\n",
    "        <b>Basis:</b> {basis}<br>\n",
    "        <b>Recode Settings:</b><br>\n",
    "        &nbsp;&nbsp;Degraded → {recode_deg}<br>\n",
    "        &nbsp;&nbsp;Stable → {recode_stable}<br>\n",
    "        &nbsp;&nbsp;Improved → {recode_imp}\n",
    "        \"\"\"\n",
    "\n",
    "        # Add polygon outline\n",
    "        folium.Polygon(\n",
    "            locations=[[coord[1], coord[0]] for coord in coords],\n",
    "            color=\"red\",\n",
    "            weight=3,\n",
    "            fill=True,\n",
    "            fillColor=\"red\",\n",
    "            fillOpacity=0.3,\n",
    "            popup=popup_content,\n",
    "        ).add_to(m)\n",
    "\n",
    "        # Add marker at center\n",
    "        folium.Marker(\n",
    "            center_poly,\n",
    "            popup=popup_content,\n",
    "            icon=folium.Icon(color=\"red\", icon=\"exclamation-sign\"),\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Add layer control\n",
    "    folium.LayerControl().add_to(m)\n",
    "\n",
    "    # Add a legend\n",
    "    legend_html = \"\"\"\n",
    "    <div style=\"position: fixed; \n",
    "                bottom: 50px; left: 50px; width: 200px; height: 90px; \n",
    "                background-color: white; border:2px solid grey; z-index:9999; \n",
    "                font-size:14px; padding: 10px\n",
    "                \">\n",
    "    <b>Legend</b><br>\n",
    "    <i class=\"fa fa-square\" style=\"color:blue\"></i> Area of Interest<br>\n",
    "    <i class=\"fa fa-square\" style=\"color:red\"></i> Error Polygons<br>\n",
    "    <i class=\"fa fa-map-marker\" style=\"color:red\"></i> Error Locations\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    # Display the map\n",
    "    print(\"🗺️ Interactive map created successfully!\")\n",
    "    print(\"   - Blue outline: Area of Interest\")\n",
    "    print(\"   - Red polygons: Error correction areas\")\n",
    "    print(\"   - Red markers: Error polygon centers\")\n",
    "    print(\"   - Click on polygons/markers for details\")\n",
    "\n",
    "    # Show the map\n",
    "    m\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⚠️ Folium not installed. Install with: pip install folium\")\n",
    "    print(\"Skipping interactive map creation...\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating interactive map: {e}\")\n",
    "    print(\"Interactive map creation failed, but other visualizations should work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d678d239",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Next Steps\n",
    "\n",
    "This notebook demonstrates the complete workflow for using the SDG 15.3.1 Error Recode algorithm:\n",
    "\n",
    "### What We Accomplished:\n",
    "✅ **API Authentication** - Successfully connected to trends.earth API  \n",
    "✅ **Job Submission** - Submitted error recode job with polygon corrections  \n",
    "✅ **Result Monitoring** - Tracked job progress and retrieved results  \n",
    "✅ **Data Visualization** - Created comprehensive maps showing before/after analysis  \n",
    "✅ **Interactive Exploration** - Generated interactive map for detailed investigation\n",
    "\n",
    "### Key Features of the Enhanced Error Recode Script:\n",
    "- **Multi-period Support**: Handles jobs with multiple time periods using filters parameter\n",
    "- **Simplified Band Selection**: Uses existing get_band_by_name() filtering functionality\n",
    "- **Error Polygon Integration**: Applies user-defined corrections to specific geographic areas\n",
    "- **Robust Error Handling**: Clear error messages and graceful failure handling\n",
    "\n",
    "### Next Steps:\n",
    "1. **Customize Parameters**: Modify the error polygons and recode values for your specific use case\n",
    "2. **Real Data Integration**: Replace synthetic data with actual S3 URIs from your analysis\n",
    "3. **Advanced Analysis**: Combine with other SDG 15.3.1 indicators (productivity, land cover)\n",
    "4. **Automation**: Integrate into larger workflows for operational monitoring\n",
    "\n",
    "### Related Resources:\n",
    "- **Statistics Analysis**: See `sdg_15_3_1_stats_example.ipynb` for complementary statistics calculation\n",
    "- **API Documentation**: trends.earth API reference for additional endpoints\n",
    "- **Algorithm Details**: SDG 15.3.1 methodology documentation\n",
    "\n",
    "### Support:\n",
    "For questions about this workflow or the trends.earth platform, consult the documentation or contact the development team."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trends.earth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
